<!DOCTYPE html>
<html>

<head>
    <!-- Google tag (gtag.js) -->

    <!-- Taken from view-source:https://voyager.minedojo.org/ -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-Q75H4YSQ8M"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-Q75H4YSQ8M');
    </script>
    <!-- Adapted from Dave Epstein's BlogGAN webpage template: https://dave.ml/blobgan/ -->
    <title>Open-Ended Instructable Embodied Agents with Memory-Augmented Large Language Models
    </title>
    <link rel="stylesheet" href="./bulma.min.css" />
    <link rel="stylesheet" href=".bulma-carousel.min.css" />
    <link rel="stylesheet" href=".bulma-slider.min.css" />
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
    <style>
        html,
        body,
        h1,
        h2,
        h3,
        h4,
        h5,
        h6 {
            /* font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; */
            font-family: 'Lato';
        }

        .cite {
            padding: 0px;
            background: #ffffff;
            font-size: 18px
        }

        .card {
            border: 1px solid #ccc
        }

        /* img { margin-bottom:-6px;} */
        p {
            font-size: 18px;
        }
    </style>
    <meta charset="UTF-8">
    <meta name="description"
        content="Open-Ended Instructable Embodied Agents with Memory-Augmented Large Language Models">
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title></title>
    <link rel="apple-touch-icon" sizes="180x180" href="apple-touch-icon.png">
    <link rel="manifest" href="site.webmanifest">
    <meta name="theme-color" content="#f5ece5">
    <link rel="mask-icon" href="safari-pinned-tab.svg" color="#276FBF">
    <meta name="msapplication-TileColor" content="#276FBF">

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <style>
        html,
        body {
            /* font-family: 'GT Ultra', sans-serif !important; */
            font-family: 'Lato' !important;
            font-weight: 400;
            font-size: 18px;
            overflow-x: hidden;
            box-sizing: border-box;
            /* color: #1f1e1d; */
            color: #000000;
            background-color: #f5ece5;
        }

        *,
        *:before,
        *:after {
            box-sizing: inherit;
        }

        header {
            text-align: center;
        }

        a {
            /* color: #276FBF !important; */
            color: #276FBF;
            text-decoration: none;
            font-weight: 400;
        }

        a:hover {
            text-decoration: underline;
            /* color: #184477 !important; */
            color: #184477;
        }

        section h3 {
            margin-bottom: 1rem;
            display: flex;
            align-items: center;
        }

        section h5,
        section h3 {
            justify-content: space-between;

            display: flex;
            align-items: center;
        }
    </style>

    <style>
        .outer {
            width: 100%;
            height: 200px;
            background-color: red;
        }

        .inner {
            position: relative;
            width: 100%;
            text-align: center;
            margin: auto;
            color: white;
            cursor: crosshair;
            user-select: none;
            -moz-user-select: none;
            -ms-user-select: none;
            -webkit-user-select: none;
        }

        .video-responsive {
        text-align: center;
        }

        @media screen and (max-width: 560px) {
        .video-responsive {
            overflow: hidden;
            padding-bottom: 56.25%;
            position: relative;
            height: 0;
        }
        .video-responsive iframe {
            left: 0;
            top: 0;
            height: 100%;
            width: 100%;
            position: absolute;
        }
        }

        .log {
            position: relative;
            width: 100%;
            text-align: center;
        }

        .inner_cat {
            position: relative;
            width: 100%;
            text-align: center;
            margin: auto;
            color: white;
            cursor: crosshair;
            user-select: none;
            -moz-user-select: none;
            -ms-user-select: none;
            -webkit-user-select: none;
        }

        .log_cat {
            position: relative;
            width: 100%;
            text-align: center;
        }

        .inner_sn {
            position: relative;
            width: 100%;
            text-align: center;
            margin: auto;
            color: white;
            cursor: crosshair;
            user-select: none;
            -moz-user-select: none;
            -ms-user-select: none;
            -webkit-user-select: none;
        }

        .log_sn {
            position: relative;
            width: 100%;
            text-align: center;
        }

        .inner_gc {
            position: relative;
            width: 100%;
            text-align: center;
            margin: auto;
            color: white;
            cursor: crosshair;
            user-select: none;
            -moz-user-select: none;
            -ms-user-select: none;
            -webkit-user-select: none;
        }

        .log_gc {
            position: relative;
            width: 100%;
            text-align: center;
        }

        .inner_shading {
            position: relative;
            width: 100%;
            text-align: center;
            margin: auto;
            color: white;
            cursor: crosshair;
            user-select: none;
            -moz-user-select: none;
            -ms-user-select: none;
            -webkit-user-select: none;
        }

        .log_shading {
            position: relative;
            width: 100%;
            text-align: center;
        }

        .inner_gqa {
            position: relative;
            width: 100%;
            text-align: center;
            margin: auto;
            color: white;
            cursor: crosshair;
            user-select: none;
            -moz-user-select: none;
            -ms-user-select: none;
            -webkit-user-select: none;
        }

        .log_gqa {
            position: relative;
            width: 100%;
            text-align: center;
        }

        .inner_demo {
            position: relative;
            width: 100%;
            text-align: center;
            margin: auto;
            color: white;
            cursor: crosshair;
            user-select: none;
            -moz-user-select: none;
            -ms-user-select: none;
            -webkit-user-select: none;
        }

        .log_demo {
            position: relative;
            width: 100%;
            text-align: center;
        }

        /* .demo_gif {
        position: relative;
        width: 50%;
        text-align: center;
        margin: auto;
        } */
    </style>


    <style>
        .project-links {
            /* width: 400px;
        height: 400px;
        position: absolute;
        left: 50%;
        top: 50%;
        transform: translate(-50%, -50%);
        display: flex;
        justify-content: center; */
            max-width: 600px;
            margin: 0 auto;
            align-items: center;
            display: flex;
            gap: 20px;
            justify-content: center;
            flex-wrap: wrap;
        }
    </style>

    <!-- Paper button -->
    <style>
        .btn-paper {
            width: 95px;
            height: 35px;
            cursor: pointer;
            border-radius: 25px;
            background: transparent;
            border: 2px solid #91C9FF;
            outline: none;
            transition: 1s ease-in-out;
            text-decoration: none;
            align-items: center;
            display: flex;
            text-align: center;
            font-weight: 500;
            color: black;
        }

        .btn-paper:hover {
            transition: 0.75s ease-in-out;
            background: #8bb2ff1e;
            text-decoration: none;
            font-weight: 500;
            color: black;
        }

        .vertical-center-paper {
            height: 80%;
            position: relative;
            /* top: 0px;
            right: 0;
            float: left; */
            padding-right: 1px;
            padding-left: 6px;
        }
    </style>

    <!-- Code button -->
    <style>
        .btn-code {
            width: 95px;
            height: 35px;
            cursor: pointer;
            border-radius: 25px;
            background: transparent;
            border: 2px solid #91C9FF;
            outline: none;
            transition: 1s ease-in-out;
            text-decoration: none;
            align-items: center;
            display: flex;
            text-align: center;
            font-weight: 500;
            color: black;
        }

        .btn-code:hover {
            transition: 0.75s ease-in-out;
            background: #8bb2ff1e;
            text-decoration: none;
            font-weight: 500;
        }

        .vertical-center-code {
            height: 60%;
            position: relative;
            /* top: 0px;
            left: 0px;
            float: left; */
            padding-right: 8px;
            padding-left: 10px;
        }
    </style>

    <!-- Citation button -->
    <style>
        .btn-citation {
            width: 110px;
            height: 35px;
            cursor: pointer;
            border-radius: 25px;
            background: transparent;
            border: 2px solid #91C9FF;
            outline: none;
            transition: 1s ease-in-out;
            text-decoration: none;
            align-items: center;
            display: flex;
            text-align: center;
            font-weight: 500;
            color: black;
        }

        .btn-citation:link {
            color: black;
        }

        .btn-citation:visited {
            color: black;
        }

        /* .btn-citation:hover {
            color: black;
        } */
        .btn-citation:active {
            color: black;
        }

        .btn-citation:hover {
            transition: 0.75s ease-in-out;
            background: #8bb2ff1e;
            text-decoration: none;
            font-weight: 500;
            color: black;
        }

        .vertical-center-cit {
            height: 70%;
            position: relative;
            /* top: 0px;
            right: 0;
            float: left; */
            padding-right: 7px;
            padding-left: 6px;
        }
    </style>

    <!-- Interactive button -->
    <style>
        .btn-interact {
            width: 133px;
            height: 35px;
            cursor: pointer;
            border-radius: 25px;
            background: transparent;
            border: 2px solid #91C9FF;
            outline: none;
            transition: 1s ease-in-out;
            text-decoration: none;
            align-items: center;
            display: flex;
            text-align: center;
            font-weight: 500;
            color: black;
        }

        .btn-interact:link {
            color: black;
        }

        .btn-interact:visited {
            color: black;
        }

        /* .btn-citation:hover {
                color: black;
            } */
        .btn-interact:active {
            color: black;
        }

        .btn-interact:hover {
            transition: 0.75s ease-in-out;
            background: #8bb2ff1e;
            text-decoration: none;
            font-weight: 500;
            color: black;
        }

        .vertical-center-interact {
            height: 70%;
            position: relative;
            /* top: 0px;
                right: 0;
                float: left; */
            padding-right: 7px;
            padding-left: 6px;
        }
    </style>

    <style>
        .vertical-center {
            height: 80%;
            position: relative;
            top: 0px;
            right: 0;
            float: left;
        }
    </style>

    <style>
        /* The grid: Four equal columns that floats next to each other */
        /* .column {
            float: left;
            width: 25% !important;
            padding: 10px;
        } */

        /* Style the images inside the grid */
        .column img {
            opacity: 0.8;
            cursor: pointer;
        }

        .column img:hover {
            opacity: 1;
        }

        /* Clear floats after the columns */
        .row:after {
            content: "";
            display: table;
            clear: both;
        }

        /* The expanding image container (positioning is needed to position the close button and the text) */
        .container {
            position: relative;
            display: none;
        }

        /* Expanding image text */
        #imgtext {
            position: absolute;
            bottom: 15px;
            left: 15px;
            color: white;
            font-size: 20px;
        }

        /* Closable button inside the image */
        .closebtn {
            position: absolute;
            top: 10px;
            right: 15px;
            color: rgb(0, 0, 0);
            font-size: 35px;
            cursor: pointer;
        }

        .centered {
            position: relative;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            color: rgb(0, 0, 0);
            background-color: rgba(0, 0, 0, 0.26);
        }

        .text-block {
            position: absolute;
            /* bottom: 25px;
        right: 20px; */
            transform: translate(-50%, -50%);
            top: 50%;
            left: 50%;
            background-color: rgba(0, 0, 0, 0.26);
            color: white;
            padding-left: 30px;
            padding-right: 30px;
        }

        .parentContainer {
            position: relative;
            text-align: center;
            color: white;
        }

        

        .column-left,
        .column-right {
        width: 50%;
        }

        .container {
        display: flex;
        padding: 0px; /* Adjust as needed */
        }

        .columns {
            justify-content: center;
        }

        .video-column {
            padding: 0; /* Remove padding */
        }
        .video-container {
            display: flex;
            flex-wrap: wrap;
            justify-content: center; /* this will center the videos */
        }
/* 
        .is-one-third-desktop {
            flex: 0 1 calc(32.333% - 4px); 
            margin: 2px; 
            max-width: 32.333%;
        } */

        /* .is-one-third-desktop {
            flex: 0 1 calc(24% - 4px); 
            margin: 2px; 
            max-width: 24%;
        } */

        .is-centered {
            text-align: center;
        }

    </style>
</head>

<body class="w3-white">
    <!-- Page Container -->
    <div class="w3-content w3-margin-top w3-margin-bottom" style="max-width:1080px;">

        <!-- The Grid -->
        <div class="w3-row-padding">

            <!-- paper container -->
            <div class="w3-display-container w3-row w3-white w3-margin-bottom">
                <div class="w3-center">
                    <h2>Open-Ended Instructable Embodied Agents with
                    Memory-Augmented Large Language Models</h2>
                    <h5><a href="https://www.gabesarch.me">Gabriel Sarch</a> &emsp;&emsp; 
                        <a href="https://www.yuewu.ml/">Yue Wu</a> &emsp;&emsp;
                        <a
                            href="https://sites.google.com/andrew.cmu.edu/tarrlab/people/michael-j-tarr">Michael
                            Tarr</a> &emsp;&emsp;
                        <a href="https://www.cs.cmu.edu/~katef/">Katerina Fragkiadaki</a> 
                    </h5>
                    <div class="w3-center">
                        <h5>Carnegie Mellon University</h5>
                    </div>
                    <div class="w3-center">
                        <h5>EMNLP 2023</h5>
                    </div>
                </div>

                <br>

                <div class="project-links">
                    <a href="https://arxiv.org/abs/2310.15127" target="_blank" class="btn-paper"
                        role="button">
                        <img src="images/paper.png" class="vertical-center-paper"> Paper
                    </a>
                    <a href="https://github.com/Gabesarch/HELPER" target="_blank" class="btn-code"
                        role="button">
                        <img src="images/code.png" class="vertical-center-code"> Code
                    </a>
                </div>

                <section class="section">
                    <div class="container is-max-widescreen">
                        <div class="columns is-multiline is-centered">
                            <div class="column is-full-mobile is-one-quarter-desktop video-column">
                                <video controls muted autoplay loop width="100%">
                                    <source src="images/task_videos_new/Example_Video6.m4v" type="video/mp4" />
                                </video>
                            </div>
                            <div class="column is-full-mobile is-one-quarter-desktop video-column">
                                <video controls muted autoplay loop width="100%">
                                    <source src="images/task_videos_new/Example_Video4.m4v" type="video/mp4" />
                                </video>
                            </div>
                            <div class="column is-full-mobile is-one-quarter-desktop video-column">
                                <video controls muted autoplay loop width="100%">
                                    <source src="images/task_videos_new/Example_Video8.m4v" type="video/mp4" />
                                </video>
                            </div>
                            <div class="column is-full-mobile is-one-quarter-desktop video-column">
                                <video controls muted autoplay loop width="100%">
                                    <source src="images/task_videos_new/Example_Video2.m4v" type="video/mp4" />
                                </video>
                            </div>
                            <div class="column is-full-mobile is-one-quarter-desktop video-column">
                                <video controls muted autoplay loop width="100%">
                                    <source src="images/task_videos_new/Example_Video9.m4v" type="video/mp4" />
                                </video>
                            </div>
                            <div class="column is-full-mobile is-one-quarter-desktop video-column">
                                <video controls muted autoplay loop width="100%">
                                    <source src="images/task_videos_new/Example_Video7.m4v" type="video/mp4" />
                                </video>
                            </div>
                            <div class="column is-full-mobile is-one-quarter-desktop video-column">
                                <video controls muted autoplay loop width="100%">
                                    <source src="images/task_videos_new/Example_Video3.m4v" type="video/mp4" />
                                </video>
                            </div>
                            <div class="column is-full-mobile is-one-quarter-desktop video-column">
                                <video controls muted autoplay loop width="100%">
                                    <source src="images/task_videos_new/Example_Video5.m4v" type="video/mp4" />
                                </video>
                            </div>
                            <div class="column is-full-mobile is-one-quarter-desktop video-column">
                                <video controls muted autoplay loop width="100%">
                                    <source src="images/task_videos_new/Example_Video1_Clean.m4v" type="video/mp4" />
                                </video>
                            </div>
                            <div class="column is-full-mobile is-one-quarter-desktop video-column">
                                <video controls muted autoplay loop width="100%">
                                    <source src="images/task_videos_new/Example_Video10.m4v" type="video/mp4" />
                                </video>
                            </div>
                            <div class="column is-full-mobile is-one-quarter-desktop video-column">
                                <video controls muted autoplay loop width="100%">
                                    <source src="images/task_videos_new/Example_Video11.m4v" type="video/mp4" />
                                </video>
                            </div>
                            <div class="column is-full-mobile is-one-quarter-desktop video-column">
                                <video controls muted autoplay loop width="100%">
                                    <source src="images/task_videos_new/Example_Video12.m4v" type="video/mp4" />
                                </video>
                            </div>
                        </div>
                    </div>
                </section>

                <br>
                <spacer type="horizontal" width="100" height="50"> </spacer>
                <br>
                
                <hr>
                <div class="w3-center">
                    <h2>Abstract</h2>
                </div>
                <p align="justify">Pre-trained and frozen LLMs can effectively map simple scene re-arrangement instructions to programs over a robot's
                visuomotor functions through appropriate few-shot example prompting. To parse open-domain natural language and adapt to
                a user's idiosyncratic procedures, not known during prompt engineering time, fixed prompts fall short. In this paper, we
                introduce HELPER, an embodied agent equipped with as external memory of language-program pairs that parses free-form
                human-robot dialogue into action programs through retrieval-augmented LLM prompting: relevant memories are retrieved
                based on the current dialogue, instruction, correction or VLM description, and used as in-context prompt examples for
                LLM querying. The memory is expanded during deployment to include pairs of user's language and action plans, to assist
                future inferences and personalize them to the user's language and routines. <b>HELPER sets a new state-of-the-art in the
                TEACh benchmark</b> in both Execution from Dialog History (EDH) and Trajectory from Dialogue (TfD), with <b>1.7x improvement
                over the previous SOTA for TfD.</b></p>
                <br>
                <br>
                <!-- <hr> -->
                <div class="w3-display-container w3-row w3-white w3-margin-bottom w3-center">
                    <!-- <h2>What can HELPER do?</h2> -->
                    <!-- <h2>How does HELPER work?</h2>
                    <p align="justify">We enhance Large Language Models (LLMs) with an external memory storing language-program pairs for in-context example
                    retrieval during task plan generation. The model processes instructions, dialogues, corrections, and visual environment
                    descriptions, retrieving pertinent memories for context-aware predictions of task plans and their adjustments. Our agent
                    implements these plans through visual input, utilizing map building, 3D object detection, state tracking, and active
                    exploration guided by the LLM's common sense for object location. Successful programs, paired with their linguistic
                    context, are archived in memory, facilitating personalized future interactions.</p> -->
                    <div class="w3-center">
                        <video width="100%" playsinline autoplay muted loop poster="images/Figure1_Revised_V12.jpg">
                            <source src="images/Figure1_Video_V2_cropped.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <br>
                    <!-- <br>
                    <spacer type="horizontal" width="100" height="50"> </spacer>
                    <br> -->
                    <!-- <h3 align="center">Framework Overview</h3>
                    <p align="justify">Helper is an an embodied agent
                    equipped with as external memory of language-program pairs that parses free-form human-robot dialogue into action programs through
                    retrieval-augmented LLM prompting. The programs are then translated into specific
                    navigation and manipulation actions from RGB input.</p> -->
                    <!-- <p align="justify">Helper is made up of the following modules:</p> -->
                    <!-- <img src="images/Full_Pipeline_Figure_V4.jpg" style="width:60%"> -->
                    <!-- <p align="justify"> -->
                    <!-- <ol>
                    <li align="justify"><b>PLANNER</b>: The PLANNER obtains the most relevant task plans from memory to prompt
                    an LLM to transform user instructions, dialogue, failure reasons, or user feedback into an executable program.</li>
                    <li align="justify"><b>Plan correction</b>: When an action fails, a pretrained vision-language model infers the failure's cause from pixel input. This
                    inferred reason, along with the top-K most relevant error correction examples from memory, is then fed into the planner
                    to generate a corrective program.</li>
                    <li align="justify"><b>EXECUTOR</b>: translates each program step into specific navigation and manipulation actions. The EXECUTOR has the following sub-components:
                        <ol type="a">
                        <li align="justify"><b>Perception</b>: The Executor builds a semantic map using an off-the-shelf object detector and monocular depth estimation network. It detects and keeps track of object states (cooked, dirty, ...) via a vision-language model.</li>
                        <li align="justify"><b>Action execution</b>: It executes navigation code steps by shortest path planning in the semantic obstacle map and executes manipulation code steps
                        by calling on a set of low-level manipulation actions (pickup(X), slice(X), etc.).</li>
                        <li align="justify"><b>Pre-condition check</b>: Verifies if the necessary preconditions for an action, and the plan is adjusted according to the current environmental and agent state.</li>
                        <li align="justify"><b>LOCATOR</b>: The LOCATOR module efficiently searches for a required object by utilizing previous user instructions and LLMs' commonsense knowledge.</li>
                        </ol>
                    </li>
                    </ol> -->
                    </p>
                    <br>
                    <br>
                    <spacer type="horizontal" width="100" height="50"> </spacer>
                    <br>
                    <h3 align="center">Memory-Augmented Prompting</h3>
                    <p align="justify">A key component of HELPER is its <b>memory of language-program pairs</b> to generate <b>tailored prompts
                        for pretrained LLMs based on the current
                        language context</b>.</p>
                    <!-- <img src="images/PlannerCombinedFigure_V5_katefversion2_combinedwfeedbackpersonal_V3.jpg" style="width:100%"> -->
                    <img src="images/WEBSITE_memory_straight.jpg" style="width:100%">
                    <br>
                    <br>
                    <spacer type="horizontal" width="100" height="50"> </spacer>
                    <br>
                    <p align="justify">The retrieved examples are added to the LLM prompt, which aids in parsing
                        diverse, and user-specific linguistic inputs for
                        planning, re-planning during failures, and
                        interpreting human feedback.</p>
                    <img src="images/WEBSITE_PlannerCombinedFigure_B.jpg" style="width:100%">
                    <br>
                    <!-- <br>
                    <br>
                    <br>
                    <spacer type="horizontal" width="100" height="50"> </spacer>
                    <br>
                    <h3 align="center">Visually-Grounded Error Correction</h3>
                    <p align="justify">HELPER uses a <b>pretrained VLM to
                    obtain an action failure reason</b> and uses it to
                    retrieve similar failure cases with solutions for
                    memory-augmented LLM failure correction.</p>
                    <img src="images/Rectifier_Figure_V1.jpg" style="width:70%"> -->
                    
                    <br>
                    <spacer type="horizontal" width="100" height="50"> </spacer>
                    <br>
                    <br>
                    <spacer type="horizontal" width="100" height="50"> </spacer>
                    <br>
                    <br>
                    <spacer type="horizontal" width="100" height="50"> </spacer>
                    <br>
                    <hr>
                    <h2>Results</h2>
                    <br>
                    <spacer type="horizontal" width="100" height="50"> </spacer>
                    <br>
                    <h3 align="center">Household Task Execution from Messy Dialogue</h3>
                    <p align="justify">We set a new <b>state-of-the-art in the TEACh benchmark</b>, where the agent is given a messy dialogue segment and is tasked to
                    infer the sequence of actions from RGB. HELPER improves
                    Trajectory from Dialogue (TfD) task success by <b>1.7x and goal-condition success by 2.1x over existing works with minimal
                    in-domain finetuning.</b></p>
                    <p align="center">TEACh TfD Validation Unseen Performance</p>
                    <img src="images/Table_TfD_Unseen.jpg" style="width:80%">
                    <br>
                    <br>
                    <spacer type="horizontal" width="100" height="50"> </spacer>
                    <br>
                    <h4 align="center">Make a salad demo with module visualizations</h4>
                    <div class="w3-center">
                        <video width="80%" controls playsinline muted loop>
                            <source src="images/Full Task video with task text.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <br>
                    <br>
                    <h4 align="center">Error correction demo with module visualizations</h4>
                    <div class="w3-center">
                        <video width="80%" controls playsinline muted loop>
                            <source src="images/Failure_video_HELPER2.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <br>
                    <br>
                    <br>
                    <spacer type="horizontal" width="100" height="50"> </spacer>
                    <br>
                    <h3 align="center">User Feedback</h3>
                    <p align="justify">Gathering user feedback can improve a home
                        robotâ€™s performance, but frequently requesting
                        feedback on a task can diminish the overall user experience. Thus, we enable HELPER to elicit sparse
                        user feedback only when it has completed execution of the program from the initial user input. <b>HELPER improves an
                            additional 1.3X in task success when incorporating just two user feedbacks.</b></p>
                    <!-- <img src="images/User_Feedback.jpg" style="width:70%"> -->
                    <br>
                    <br>
                    <!-- <br>
                    <spacer type="horizontal" width="100" height="50"> </spacer>
                    <br> -->
                    <p align="center"><b>Demo:</b> Clean all cookware with user feedback<br>(skip to 0:41 for user feedback saying HELPER
                        missed cleaning the pot)</p>
                    <video controls playsinline autoplay muted loop width="50%" poster="images/user_feedback_thumbnail.jpg">
                        <source src="images/task_videos_new/4f4013ceab294a80_3864.tfd_4f4013ceab294a80_3864_145_e31f2cd6a8b6545446fa.mp4" type="video/mp4" />
                    </video>
                    <br>
                    <br>
                    <p align="center"><b>Demo:</b> Make breakfast with user feedback<br>(skip to 2:54 for user feedback saying did not put
                        tomato & lettuce slice on plate)</p>
                    <video controls playsinline autoplay muted loop width="50%" poster="images/user_feedback_thumbnail.jpg">
                        <source src="images/task_videos_new/c66573f82df8618c_aad3.tfd_c66573f82df8618c_aad3_80_b5980228dfd5fc4d1ce9.mp4"
                            type="video/mp4" />
                    </video>
                    <br>
                    <br>
                    <spacer type="horizontal" width="100" height="50"> </spacer>
                    <br>
                    <br>
                    <spacer type="horizontal" width="100" height="50"> </spacer>
                    <br>
                    <h3 align="center">User Personalization</h3>
                    <p align="justify">HELPER expands its
                    memory of programs with successful executions of user specific procedures; it then
                    recalls them and adapt them in future interactions with the user, allowing for user-personalized references.</p>
                    <p align="justify">We test HELPER on its ability retrieve a personalized routines and adapt them to accomodate zero,
                        one, two, or three changes (10 each) from the original plan. <b>Of the 40 inputs tested, HELPER successfully
                            recalled and adapted all but three personalized routines.</b></p>
                    <p align="justify">An example sample from the evaluation is shown below of the original instruction used to generate the personalized program and add it to memory, evaluation instructions for zero, one, two, and three requested changes of
                        the routine.</p>
                    <p align="justify"><b>Original Instruction:</b> <font color="#9900FF">"Make me a salad. The name of this salad is called the David salad. The
                    salad has two slices of tomato and three slices of lettuce on a clean plate."</font></p>
                    
                    <p align="justify"><b>No Change Instruction:</b> <font color="#9900FF">"Make me the David salad"</font></p>
                    
                    <p align="justify"><b>One Change Instruction:</b> <font color="#9900FF">"Make me the David salad with a slice of potato"</font></p>
                    
                    <p align="justify"><b>Two Change Instruction:</b> <font color="#9900FF">"Make me the David salad but add a slice of potato and add one slice of lettuce"</font></p>
                    
                    <p align="justify"><b>Three Change Instruction:</b> <font color="#9900FF">"Make me the David salad and add a slice of potato, add one slice of lettuce, and bring a fork with it"</font></p>
                    <br>
                    <spacer type="horizontal" width="100" height="50"> </spacer>
                    <br>
                    <hr>
                </div>
                <h4>See our paper for more!</h4>


                <section id="citation">
                    <h2>Citation</h2>
                    <div class="cit_cont">
                        <pre style="background-color:#F5F5F5;"><code><font size="-1">@proceedings{findings-2023-findings-association-linguistics-emnlp,
                        title = "Findings of the Association for Computational Linguistics: EMNLP 2023",
                        editor = "Sarch, Gabriel and
                        Wu, Yue and
                        Tarr, Michael and
                        Fragkiadaki, Katerina",
                        month = dec,
                        year = "2023",
                        publisher = "Association for Computational Linguistics",
                        }</font></code></pre>
                    </div>
                </section>
                <hr>
                <br>
                <br>

                <!-- end paper container -->

            </div><!-- End Grid -->
        </div><!-- End Page Container -->

</body>

</html>